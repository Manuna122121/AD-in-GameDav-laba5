Использование данных и искусственного интеллекта в игровой разработке
Отчёт по лабораторной работе №5
Автор отчёта:

Прокошева Мария Евгеньевна
Учебная группа: РИ-230941
| Задание |	Выполнено |	Оценка |
| Задание 1 |	✔️ |	? |
| Задание 2 |	✔️	| ? |
| Задание 3 |	✔️ |	? |
[Все задачи успешно выполнены]

Рецензенты:

к.т.н., доцент Денисов Д.В.
к.э.н., доцент Панов М.А.
ст. преподаватель Фадеев В.О.
Цель работы
Научиться использовать инструменты машинного обучения для их последующей интеграции в игровой движок Unity.

Введение
Пример 1: Описание задания
Цель: создать ML-агента, который управляет движением шара. Шар должен находить и взаимодействовать с перемещающимся кубом в случайных координатах на плоскости.

 ![image](https://github.com/user-attachments/assets/6555f49f-c50f-45a6-a3cb-41543a2d1c7b)


В ходе выполнения задания я настроила сцену, добавила визуальные улучшения и элементы интерфейса. Для проекта была выбрана Unity URP вместо стандартной версии для более качественной графики. После подготовки сцены проведено обучение модели. Результаты работы приведены ниже.
![image](https://github.com/user-attachments/assets/7061c3c0-e2ea-4493-812d-5833c61ade28)

 

Обучение прошло успешно, хотя в некоторых случаях шарик не успевает корректно реагировать на изменения, если куб появляется далеко или вне видимости. Повторное обучение уменьшило количество подобных ситуаций, но полностью устранить их не удалось из-за ограниченности пространства и случайного размещения куба.

 ![image](https://github.com/user-attachments/assets/ac239ee5-4ca7-4650-a23c-99cc59ce6930)


Проект доступен в репозитории по [ссылке](https://github.com/Manuna122121/).
Результат выполнения ниже:
 ![image](https://github.com/user-attachments/assets/8624de4b-4603-4166-89ad-1b0984b56237)


Пример 2: Выполнение задания
В соответствии с методическими рекомендациями я загрузила и подготовила проект. После настройки параметров проведено обучение модели, а затем выполнено её тестирование.

Процесс обучения:

 ![image](https://github.com/user-attachments/assets/ce2f6f26-7d5b-4030-828b-437b32b9cdc9)


Результаты тестирования:

 ![image](https://github.com/user-attachments/assets/07a08af9-9666-43b3-ae82-d12ed8a93730)

Загрузил Unity проект с решением в репозиторий, в директорию ML-Agent-EconomicModel.

 ![image](https://github.com/user-attachments/assets/647351a1-483f-46df-a819-9cf1cc0ee4f3)



График, иллюстрирующий обучение модели:

 ![image](https://github.com/user-attachments/assets/35ed9b9d-f680-4b0d-8066-119bfb5e6771)


На графике заметно, что на поздних этапах обучения произошло переобучение модели, из-за чего её эффективность снизилась.

Выполнение заданий
Задание 1
Изучение влияния коэффициента корреляции на процесс обучения.

Коэффициент корреляции отражает взаимосвязь между различными параметрами. В данном контексте он определяет, насколько эффективно агент реагирует на изменения окружающей среды.

Эксперимент: я увеличила допустимое расстояние до цели с 1.42 до 2.1. Результаты показали, что вознаграждения стали более стабильными, а среднее отклонение уменьшилось. Это подтверждает влияние корреляции на адаптивность агента к условиям задачи.
![image](https://github.com/user-attachments/assets/3605ca25-4fc4-4fce-82a8-6ebdffbd9991)
![image](https://github.com/user-attachments/assets/5ae63c06-3445-46cd-8181-0a4a8431d972)
![image](https://github.com/user-attachments/assets/f2b01ade-05f2-464a-b86c-914729e14149)

Задание 2
Влияние изменений параметров файла yaml на процесс обучения.

Рассмотренные параметры:

buffer_size: увеличение размера буфера привело к ускорению обучения за счёт использования большего объёма данных.
num_epoch: увеличение количества эпох обучения не дало существенных изменений, так как модель не требовала доработки на исходном наборе данных.
learning_rate: изменения скорости обучения также не оказали значимого влияния.
Задание 3
Применение ML-агентов в игровых сценариях.

Первый агент: подходит для задач, связанных с поиском целей в динамичной среде, например, для управления врагами, которые преследуют игрока в условиях сложных препятствий.
Второй агент: оптимален для экономических стратегий, где NPC выполняют задачи, связанные с добычей ресурсов. Такой подход обеспечивает гибкость при изменении окружения.
Использование ML-агентов особенно полезно там, где классические алгоритмы требуют значительных затрат на реализацию.

Выводы
В рамках лабораторной работы я изучила основные принципы интеграции машинного обучения в проекты на Unity. Были рассмотрены задачи для двух ML-агентов, а также протестированы различные настройки их обучения. Полученные знания расширяют возможности применения современных технологий искусственного интеллекта в игровой разработке.

